{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "573f0ab2",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f28f09da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JAX, Flax, and Optax for the model and training\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "import optax\n",
    "\n",
    "# Data loading and image processing\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f6500",
   "metadata": {},
   "source": [
    "# Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bc75695",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SIZE = (300, 300)\n",
    "CAR_CATEGORY_ID = 2 \n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eea7e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_car(example):\n",
    "    \"\"\"Filter function to check if an image contains a car.\"\"\"\n",
    "    return any(category == CAR_CATEGORY_ID for category in example['objects']['category'])\n",
    "\n",
    "def preprocess_with_padding(example, target_size=(300, 300), bg_color=(128, 128, 128)):\n",
    "    \"\"\"\n",
    "    Resizes and pads an image to a target square size while maintaining aspect ratio,\n",
    "    and correctly adjusts the bounding box coordinates.\n",
    "    \"\"\"\n",
    "    # --- THIS IS THE CORRECTED LINE ---\n",
    "    # We directly use the decoded Pillow image object from the dataset.\n",
    "    image = example['image'].convert(\"RGB\")\n",
    "    \n",
    "    original_w, original_h = image.size\n",
    "\n",
    "    # Calculate scaling ratio and new dimensions\n",
    "    ratio = min(target_size[0] / original_w, target_size[1] / original_h)\n",
    "    new_w, new_h = int(original_w * ratio), int(original_h * ratio)\n",
    "    resized_image = image.resize((new_w, new_h), Image.Resampling.LANCZOS)\n",
    "\n",
    "    # Create a padded canvas and paste the resized image\n",
    "    padded_image = Image.new(\"RGB\", target_size, bg_color)\n",
    "    paste_x = (target_size[0] - new_w) // 2\n",
    "    paste_y = (target_size[1] - new_h) // 2\n",
    "    padded_image.paste(resized_image, (paste_x, paste_y))\n",
    "    \n",
    "    # Convert to a normalized NumPy array\n",
    "    image_np = np.array(padded_image, dtype=np.float32) / 255.0\n",
    "\n",
    "    # Adjust bounding boxes by scaling and adding the padding offset\n",
    "    new_boxes, new_labels = [], []\n",
    "    for bbox, category in zip(example['objects']['bbox'], example['objects']['category']):\n",
    "        x_min, y_min, w, h = bbox\n",
    "        new_boxes.append([(x_min*ratio)+paste_x, (y_min*ratio)+paste_y, w*ratio, h*ratio])\n",
    "        new_labels.append(category)\n",
    "\n",
    "    return {\n",
    "        'image': image_np, \n",
    "        'bboxes': np.array(new_boxes, dtype=np.float32), \n",
    "        'labels': np.array(new_labels, dtype=np.int32)\n",
    "    }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Pads bboxes and labels to the max length in a batch to create uniform tensors.\"\"\"\n",
    "    max_objects = max(len(item['labels']) for item in batch)\n",
    "    if max_objects == 0: max_objects = 1  # Avoid shape errors for images with no objects\n",
    "    \n",
    "    padded_batch = {'image': [], 'bboxes': [], 'labels': []}\n",
    "    for item in batch:\n",
    "        num_objects = len(item['labels'])\n",
    "        padding_needed = max_objects - num_objects\n",
    "        \n",
    "        # Use -1 as the padding value for bboxes and labels\n",
    "        padded_bboxes = np.pad(item['bboxes'], ((0, padding_needed), (0, 0)), mode='constant', constant_values=-1)\n",
    "        padded_labels = np.pad(item['labels'], (0, padding_needed), mode='constant', constant_values=-1)\n",
    "        \n",
    "        padded_batch['image'].append(item['image'])\n",
    "        padded_batch['bboxes'].append(padded_bboxes)\n",
    "        padded_batch['labels'].append(padded_labels)\n",
    "        \n",
    "    # Stack individual examples and convert to JAX arrays\n",
    "    return {k: jnp.array(np.stack(v, axis=0)) for k, v in padded_batch.items()}\n",
    "\n",
    "def create_data_loader(dataset, batch_size, shuffle=True):\n",
    "    \"\"\"A generator function that yields batches of data.\"\"\"\n",
    "    if shuffle:\n",
    "        # buffer_size controls how many elements are loaded into memory for shuffling\n",
    "        dataset = dataset.shuffle(buffer_size=1000)\n",
    "    \n",
    "    batch = []\n",
    "    for example in dataset:\n",
    "        batch.append(example)\n",
    "        if len(batch) == batch_size:\n",
    "            yield collate_fn(batch)\n",
    "            batch = []\n",
    "            \n",
    "    if batch: # Yield the last, potentially smaller batch\n",
    "        yield collate_fn(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "718a3131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loader created successfully!\n",
      "Testing the first batch...\n",
      "Image batch shape: (16, 300, 300, 3)\n",
      "BBoxes batch shape: (16, 22, 4)\n",
      "Labels batch shape: (16, 22)\n"
     ]
    }
   ],
   "source": [
    "# Load the raw dataset (streaming to save disk space)\n",
    "raw_ds = load_dataset(\"detection-datasets/coco\", split=\"train\", streaming=True)\n",
    "\n",
    "# Apply filtering and preprocessing\n",
    "car_ds = raw_ds.filter(contains_car)\n",
    "processed_ds = car_ds.map(preprocess_with_padding)\n",
    "\n",
    "# Create the final data loader\n",
    "# NOTE: .take(1000) is used for a quick test. Remove it for full training.\n",
    "train_loader = create_data_loader(processed_ds.take(1000), BATCH_SIZE)\n",
    "\n",
    "# --- 4. Test the Loader ---\n",
    "print(\"✅ Data loader created successfully!\")\n",
    "print(\"Testing the first batch...\")\n",
    "\n",
    "for first_batch in train_loader:\n",
    "    print(f\"Image batch shape: {first_batch['image'].shape}\")\n",
    "    print(f\"BBoxes batch shape: {first_batch['bboxes'].shape}\")\n",
    "    print(f\"Labels batch shape: {first_batch['labels'].shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01494069",
   "metadata": {},
   "source": [
    "# Pre-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efbd9eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2Norm(nn.Module):\n",
    "    \"\"\"L2 Normalization layer with a learnable scale parameter.\"\"\"\n",
    "    n_channels: int\n",
    "    initial_scale: float = 20.0\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        # Normalize along the channel dimension (axis=-1)\n",
    "        norm = jnp.sqrt(jnp.sum(x**2, axis=-1, keepdims=True))\n",
    "        x_norm = x / (norm + 1e-10)\n",
    "        \n",
    "        # Add a learnable scaling factor for each channel\n",
    "        scale = self.param('scale', nn.initializers.constant(self.initial_scale), (self.n_channels,))\n",
    "        # Reshape scale for broadcasting: (C,) -> (1, 1, 1, C)\n",
    "        scale = scale.reshape((1,) * (x.ndim - 1) + (-1,))\n",
    "        \n",
    "        return x_norm * scale\n",
    "\n",
    "class SSD(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard SSD300 model with a VGG16-based backbone.\n",
    "    \"\"\"\n",
    "    num_classes: int\n",
    "    num_anchors_per_location: tuple\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        total_classes = self.num_classes + 1\n",
    "        feature_maps = []\n",
    "\n",
    "        # --- 1. VGG16 Backbone ---\n",
    "        # Block 1\n",
    "        x = nn.Conv(features=64, kernel_size=(3, 3), padding='SAME', name='conv1_1')(x); x = nn.relu(x)\n",
    "        x = nn.Conv(features=64, kernel_size=(3, 3), padding='SAME', name='conv1_2')(x); x = nn.relu(x)\n",
    "        x = nn.max_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        # Block 2\n",
    "        x = nn.Conv(features=128, kernel_size=(3, 3), padding='SAME', name='conv2_1')(x); x = nn.relu(x)\n",
    "        x = nn.Conv(features=128, kernel_size=(3, 3), padding='SAME', name='conv2_2')(x); x = nn.relu(x)\n",
    "        x = nn.max_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        # Block 3\n",
    "        x = nn.Conv(features=256, kernel_size=(3, 3), padding='SAME', name='conv3_1')(x); x = nn.relu(x)\n",
    "        x = nn.Conv(features=256, kernel_size=(3, 3), padding='SAME', name='conv3_2')(x); x = nn.relu(x)\n",
    "        x = nn.Conv(features=256, kernel_size=(3, 3), padding='SAME', name='conv3_3')(x); x = nn.relu(x)\n",
    "        x = nn.max_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        # Block 4 -> Source for first feature map (Conv4_3)\n",
    "        x = nn.Conv(features=512, kernel_size=(3, 3), padding='SAME', name='conv4_1')(x); x = nn.relu(x)\n",
    "        x = nn.Conv(features=512, kernel_size=(3, 3), padding='SAME', name='conv4_2')(x); x = nn.relu(x)\n",
    "        x = nn.Conv(features=512, kernel_size=(3, 3), padding='SAME', name='conv4_3')(x); x = nn.relu(x)\n",
    "        \n",
    "        # >> Add first feature map (38x38) with L2 normalization <<\n",
    "        fm1 = L2Norm(n_channels=512, name='conv4_3_norm')(x)\n",
    "        feature_maps.append(fm1)\n",
    "\n",
    "        x = nn.max_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        # Block 5\n",
    "        x = nn.Conv(features=512, kernel_size=(3, 3), padding='SAME', name='conv5_1')(x); x = nn.relu(x)\n",
    "        x = nn.Conv(features=512, kernel_size=(3, 3), padding='SAME', name='conv5_2')(x); x = nn.relu(x)\n",
    "        x = nn.Conv(features=512, kernel_size=(3, 3), padding='SAME', name='conv5_3')(x); x = nn.relu(x)\n",
    "        x = nn.max_pool(x, window_shape=(3, 3), strides=(1, 1), padding='SAME') # Modified pooling\n",
    "        \n",
    "        # Converted FC layers of VGG -> Source for second feature map\n",
    "        x = nn.Conv(features=1024, kernel_size=(3, 3), padding='SAME', name='conv6')(x); x = nn.relu(x)\n",
    "        x = nn.Conv(features=1024, kernel_size=(1, 1), padding='SAME', name='conv7')(x); x = nn.relu(x)\n",
    "        \n",
    "        # >> Add second feature map (19x19) <<\n",
    "        feature_maps.append(x)\n",
    "\n",
    "        # --- 2. Extra Feature Layers ---\n",
    "        # Extra Layer 1 -> produces 10x10 feature map\n",
    "        x = nn.Conv(features=256, kernel_size=(1, 1), padding='SAME', name='extra1_1')(x); x = nn.relu(x)\n",
    "        x = nn.Conv(features=512, kernel_size=(3, 3), strides=(2, 2), padding='SAME', name='extra1_2')(x); x = nn.relu(x)\n",
    "        feature_maps.append(x)\n",
    "        \n",
    "        # Extra Layer 2 -> produces 5x5 feature map\n",
    "        x = nn.Conv(features=128, kernel_size=(1, 1), padding='SAME', name='extra2_1')(x); x = nn.relu(x)\n",
    "        x = nn.Conv(features=256, kernel_size=(3, 3), strides=(2, 2), padding='SAME', name='extra2_2')(x); x = nn.relu(x)\n",
    "        feature_maps.append(x)\n",
    "        \n",
    "        # Extra Layer 3 -> produces 3x3 feature map\n",
    "        x = nn.Conv(features=128, kernel_size=(1, 1), padding='SAME', name='extra3_1')(x); x = nn.relu(x)\n",
    "        x = nn.Conv(features=256, kernel_size=(3, 3), padding='VALID', name='extra3_2')(x); x = nn.relu(x)\n",
    "        feature_maps.append(x)\n",
    "        \n",
    "        # Extra Layer 4 -> produces 1x1 feature map\n",
    "        x = nn.Conv(features=128, kernel_size=(1, 1), padding='SAME', name='extra4_1')(x); x = nn.relu(x)\n",
    "        x = nn.Conv(features=256, kernel_size=(3, 3), padding='VALID', name='extra4_2')(x); x = nn.relu(x)\n",
    "        feature_maps.append(x)\n",
    "\n",
    "        # --- 3. Prediction Heads ---\n",
    "        loc_preds, conf_preds = [], []\n",
    "        for i, fm in enumerate(feature_maps):\n",
    "            num_anchors = self.num_anchors_per_location[i]\n",
    "            # Location head\n",
    "            loc_pred = nn.Conv(features=num_anchors * 4, kernel_size=(3, 3), padding='SAME', name=f'loc_head_{i}')(fm)\n",
    "            loc_preds.append(loc_pred.reshape((loc_pred.shape[0], -1, 4)))\n",
    "            # Confidence head\n",
    "            conf_pred = nn.Conv(features=num_anchors * total_classes, kernel_size=(3, 3), padding='SAME', name=f'conf_head_{i}')(fm)\n",
    "            conf_preds.append(conf_pred.reshape((conf_pred.shape[0], -1, total_classes)))\n",
    "\n",
    "        return jnp.concatenate(loc_preds, axis=1), jnp.concatenate(conf_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b170c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SSD300 model initialized successfully!\n",
      "\n",
      "--- Output Shapes ---\n",
      "Location predictions shape: (16, 8096, 4)\n",
      "Confidence predictions shape: (16, 8096, 2)\n"
     ]
    }
   ],
   "source": [
    "# We are still only detecting cars\n",
    "NUM_CLASSES = 1 \n",
    "\n",
    "# THIS IS THE STANDARD CONFIGURATION for an SSD300 with 6 feature maps\n",
    "ANCHORS_PER_LOCATION = (4, 6, 6, 6, 4, 4)\n",
    "\n",
    "# 1. Create a PRNG key for initialization\n",
    "key = jax.random.PRNGKey(0)\n",
    "\n",
    "# 2. Instantiate the new SSD300 model\n",
    "model = SSD(num_classes=NUM_CLASSES, num_anchors_per_location=ANCHORS_PER_LOCATION)\n",
    "\n",
    "# 3. Create a dummy input batch\n",
    "dummy_input_batch = jnp.ones((BATCH_SIZE, TARGET_SIZE[0], TARGET_SIZE[1], 3))\n",
    "\n",
    "# 4. Initialize the model's parameters\n",
    "# Note: This will take a moment longer as the model is much larger\n",
    "params = model.init(key, dummy_input_batch)['params']\n",
    "print(\"✅ SSD300 model initialized successfully!\")\n",
    "\n",
    "# 5. Apply the model to get output shapes\n",
    "loc_predictions, conf_predictions = model.apply({'params': params}, dummy_input_batch)\n",
    "\n",
    "print(\"\\n--- Output Shapes ---\")\n",
    "print(f\"Location predictions shape: {loc_predictions.shape}\")\n",
    "print(f\"Confidence predictions shape: {conf_predictions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fea27aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Generated default boxes successfully!\n",
      "Shape of default boxes tensor: (8732, 4)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def generate_default_boxes():\n",
    "    \"\"\"Generates the 8732 default anchor boxes for the SSD300 architecture.\"\"\"\n",
    "    # Configuration from the original SSD paper\n",
    "    feature_map_sizes = [38, 19, 10, 5, 3, 1]\n",
    "    min_sizes = [30, 60, 111, 162, 213, 264]\n",
    "    max_sizes = [60, 111, 162, 213, 264, 315]\n",
    "    aspect_ratios = [[2], [2, 3], [2, 3], [2, 3], [2], [2]]\n",
    "    \n",
    "    all_default_boxes = []\n",
    "    \n",
    "    for i in range(len(feature_map_sizes)):\n",
    "        fm_size = feature_map_sizes[i]\n",
    "        \n",
    "        # Create a grid of center points\n",
    "        # The centers are normalized to be between 0 and 1\n",
    "        x_centers = (jnp.arange(fm_size) + 0.5) / fm_size\n",
    "        y_centers = (jnp.arange(fm_size) + 0.5) / fm_size\n",
    "        \n",
    "        for y in y_centers:\n",
    "            for x in x_centers:\n",
    "                # Box 1: Small square box\n",
    "                s_k = min_sizes[i] / TARGET_SIZE[0]\n",
    "                all_default_boxes.append([x, y, s_k, s_k])\n",
    "                \n",
    "                # Box 2: Large square box\n",
    "                s_k_prime = math.sqrt(s_k * (max_sizes[i] / TARGET_SIZE[0]))\n",
    "                all_default_boxes.append([x, y, s_k_prime, s_k_prime])\n",
    "\n",
    "                # Additional boxes based on aspect ratios\n",
    "                for ar in aspect_ratios[i]:\n",
    "                    all_default_boxes.append([x, y, s_k * math.sqrt(ar), s_k / math.sqrt(ar)])\n",
    "                    all_default_boxes.append([x, y, s_k / math.sqrt(ar), s_k * math.sqrt(ar)])\n",
    "\n",
    "    # The boxes are currently in [center_x, center_y, width, height] format\n",
    "    default_boxes_tensor = jnp.array(all_default_boxes, dtype=jnp.float32)\n",
    "    \n",
    "    # Clip box coordinates to be within [0, 1]\n",
    "    default_boxes_tensor = jnp.clip(default_boxes_tensor, 0.0, 1.0)\n",
    "    \n",
    "    return default_boxes_tensor\n",
    "\n",
    "# Generate the boxes and inspect the shape\n",
    "default_boxes = generate_default_boxes()\n",
    "print(f\"✅ Generated default boxes successfully!\")\n",
    "print(f\"Shape of default boxes tensor: {default_boxes.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bcfd53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_hw_to_corners(boxes):\n",
    "    \"\"\"Converts boxes from [x_min, y_min, w, h] to [x_min, y_min, x_max, y_max].\"\"\"\n",
    "    return jnp.concatenate([boxes[..., :2], boxes[..., :2] + boxes[..., 2:]], axis=-1)\n",
    "\n",
    "def box_corners_to_hw(boxes):\n",
    "    \"\"\"Converts boxes from [x_min, y_min, x_max, y_max] to [x_min, y_min, w, h].\"\"\"\n",
    "    return jnp.concatenate([boxes[..., :2], boxes[..., 2:] - boxes[..., :2]], axis=-1)\n",
    "\n",
    "def box_center_to_corners(boxes):\n",
    "    \"\"\"Converts boxes from [cx, cy, w, h] to [x_min, y_min, x_max, y_max].\"\"\"\n",
    "    return jnp.concatenate([boxes[..., :2] - boxes[..., 2:] / 2,\n",
    "                           boxes[..., :2] + boxes[..., 2:] / 2], axis=-1)\n",
    "\n",
    "\n",
    "def jaccard_overlap(boxes1, boxes2):\n",
    "    \"\"\"Calculates intersection over union for batch of boxes.\n",
    "    Args:\n",
    "        boxes1: (N, 4) in corner format [xmin, ymin, xmax, ymax]\n",
    "        boxes2: (M, 4) in corner format [xmin, ymin, xmax, ymax]\n",
    "    Returns:\n",
    "        iou: (N, M) matrix of IoU values.\n",
    "    \"\"\"\n",
    "    # Find intersection corners\n",
    "    xy_max = jnp.minimum(boxes1[:, None, 2:], boxes2[None, :, 2:])\n",
    "    xy_min = jnp.maximum(boxes1[:, None, :2], boxes2[None, :, :2])\n",
    "    \n",
    "    # Clip to ensure intersection is never negative\n",
    "    inter_dims = jnp.clip(xy_max - xy_min, a_min=0)\n",
    "    inter_area = inter_dims[..., 0] * inter_dims[..., 1]\n",
    "\n",
    "    # Calculate individual box areas\n",
    "    area1 = (boxes1[:, 2] - boxes1[:, 0]) * (boxes1[:, 3] - boxes1[:, 1])\n",
    "    area2 = (boxes2[:, 2] - boxes2[:, 0]) * (boxes2[:, 3] - boxes2[:, 1])\n",
    "    \n",
    "    # Calculate union\n",
    "    union_area = area1[:, None] + area2[None, :] - inter_area\n",
    "    \n",
    "    return inter_area / (union_area + 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "579bfb62",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'optax.losses' has no attribute 'smooth_l1_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     49\u001b[39m dummy_conf_preds = jax.random.normal(key, shape=(BATCH_SIZE, \u001b[32m8732\u001b[39m, NUM_CLASSES + \u001b[32m1\u001b[39m))\n\u001b[32m     50\u001b[39m dummy_gt_batch = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m loss_value = \u001b[43mmultibox_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdummy_loc_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdummy_conf_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdummy_gt_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbboxes\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdummy_gt_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabels\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdefault_boxes\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ Loss function defined and tested successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     61\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCalculated a dummy loss value of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_value\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mmultibox_loss\u001b[39m\u001b[34m(loc_preds, conf_preds, gt_boxes, gt_labels, default_boxes, neg_pos_ratio)\u001b[39m\n\u001b[32m     31\u001b[39m pos_mask_batch = true_confs > \u001b[32m0\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Using the correct function path for modern Optax\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m loc_loss = \u001b[43moptax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlosses\u001b[49m\u001b[43m.\u001b[49m\u001b[43msmooth_l1_loss\u001b[49m(loc_preds[pos_mask_batch], true_locs[pos_mask_batch]).sum()\n\u001b[32m     35\u001b[39m conf_loss_all = optax.losses.softmax_cross_entropy_with_integer_labels(conf_preds, true_confs)\n\u001b[32m     37\u001b[39m pos_conf_loss = conf_loss_all[pos_mask_batch].sum()\n",
      "\u001b[31mAttributeError\u001b[39m: module 'optax.losses' has no attribute 'smooth_l1_loss'"
     ]
    }
   ],
   "source": [
    "# Cell 9 (Definitively Correct Version)\n",
    "def multibox_loss(loc_preds, conf_preds, gt_boxes, gt_labels, default_boxes, neg_pos_ratio=3):\n",
    "    batch_size = gt_labels.shape[0]\n",
    "    num_default_boxes = default_boxes.shape[0]\n",
    "\n",
    "    default_boxes_corners = box_center_to_corners(default_boxes)\n",
    "    true_locs = jnp.zeros_like(loc_preds)\n",
    "    true_confs = jnp.zeros((batch_size, num_default_boxes), dtype=jnp.int32)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        mask = gt_labels[i] > -1\n",
    "        image_gt_boxes, image_gt_labels = gt_boxes[i][mask], gt_labels[i][mask]\n",
    "        if image_gt_boxes.shape[0] == 0: continue\n",
    "        image_gt_boxes_corners = box_hw_to_corners(image_gt_boxes / TARGET_SIZE[0])\n",
    "        overlaps = jaccard_overlap(default_boxes_corners, image_gt_boxes_corners)\n",
    "        best_gt_overlap, best_gt_idx = overlaps.max(axis=1), overlaps.argmax(axis=1)\n",
    "        pos_mask = best_gt_overlap > 0.5\n",
    "        matched_gt_labels, matched_gt_boxes = image_gt_labels[best_gt_idx], image_gt_boxes[best_gt_idx]\n",
    "        conf = jnp.where(pos_mask, matched_gt_labels, 0)\n",
    "        cx, cy = matched_gt_boxes[:, 0] + matched_gt_boxes[:, 2] / 2, matched_gt_boxes[:, 1] + matched_gt_boxes[:, 3] / 2\n",
    "        matched_gt_boxes_center = jnp.stack([cx, cy, matched_gt_boxes[:, 2], matched_gt_boxes[:, 3]], axis=-1)\n",
    "        matched_gt_boxes_center /= TARGET_SIZE[0]\n",
    "        offset_cx = (matched_gt_boxes_center[:, 0] - default_boxes[:, 0]) / default_boxes[:, 2]\n",
    "        offset_cy = (matched_gt_boxes_center[:, 1] - default_boxes[:, 1]) / default_boxes[:, 3]\n",
    "        offset_w = jnp.log(matched_gt_boxes_center[:, 2] / default_boxes[:, 2])\n",
    "        offset_h = jnp.log(matched_gt_boxes_center[:, 3] / default_boxes[:, 3])\n",
    "        loc = jnp.stack([offset_cx, offset_cy, offset_w, offset_h], axis=-1)\n",
    "        true_locs = true_locs.at[i].set(jnp.where(pos_mask[:, None], loc, 0))\n",
    "        true_confs = true_confs.at[i].set(conf)\n",
    "\n",
    "    pos_mask_batch = true_confs > 0\n",
    "    \n",
    "    # Using the correct function path for modern Optax\n",
    "    loc_loss = optax.losses.smooth_l1_loss(loc_preds[pos_mask_batch], true_locs[pos_mask_batch]).sum()\n",
    "    conf_loss_all = optax.losses.softmax_cross_entropy_with_integer_labels(conf_preds, true_confs)\n",
    "    \n",
    "    pos_conf_loss = conf_loss_all[pos_mask_batch].sum()\n",
    "    neg_conf_loss = conf_loss_all.copy().at[pos_mask_batch].set(0)\n",
    "    num_positives = pos_mask_batch.sum()\n",
    "    num_negatives = num_positives * neg_pos_ratio\n",
    "    neg_conf_loss_sorted = jnp.sort(neg_conf_loss.flatten())[::-1]\n",
    "    hard_neg_loss = neg_conf_loss_sorted[:num_negatives.astype(int)].sum()\n",
    "\n",
    "    total_loss = (loc_loss + pos_conf_loss + hard_neg_loss) / jnp.maximum(1, num_positives)\n",
    "    return total_loss\n",
    "\n",
    "# --- Test the loss function with dummy data ---\n",
    "dummy_loc_preds = jax.random.normal(key, shape=(BATCH_SIZE, 8732, 4))\n",
    "dummy_conf_preds = jax.random.normal(key, shape=(BATCH_SIZE, 8732, NUM_CLASSES + 1))\n",
    "dummy_gt_batch = next(iter(train_loader))\n",
    "\n",
    "loss_value = multibox_loss(\n",
    "    dummy_loc_preds, \n",
    "    dummy_conf_preds, \n",
    "    dummy_gt_batch['bboxes'], \n",
    "    dummy_gt_batch['labels'],\n",
    "    default_boxes\n",
    ")\n",
    "\n",
    "print(f\"✅ Loss function defined and tested successfully!\")\n",
    "print(f\"Calculated a dummy loss value of: {loss_value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
